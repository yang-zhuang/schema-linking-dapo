# Schema Linking with DAPO ç®—æ³•

[![Python ç‰ˆæœ¬](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![è®¸å¯è¯](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)

åŸºäº **DAPO** ç®—æ³•çš„ Text-to-SQL æ¨¡å¼é€‰æ‹©å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚æœ¬é¡¹ç›®åŸºäº SCHEMA-R1 è®ºæ–‡ï¼Œå®ç°äº†æ”¹è¿›çš„è®­ç»ƒæ–¹æ³•å’Œè‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ï¼ŒåŒ…å«å®Œæ•´çš„æ¨¡å‹è¯„ä¼°ç³»ç»Ÿã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ä¸“æ³¨äº Text-to-SQL ç³»ç»Ÿä¸­çš„ **æ¨¡å¼é“¾æ¥ï¼ˆschema linkingï¼‰** ä»»åŠ¡ï¼Œå³ä»æ•°æ®åº“æ¨¡å¼ä¸­é€‰æ‹©æœ€ç›¸å…³çš„è¡¨å’Œåˆ—æ¥å›ç­”è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚

### æ ¸å¿ƒç‰¹æ€§ï¼š
- **DAPO ç®—æ³•**ï¼šå®ç°ç›´æ¥ä¼˜åŠ¿ç­–ç•¥ä¼˜åŒ–ï¼Œæä¾›æ›´å¥½çš„è®­ç»ƒç¨³å®šæ€§
- **è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°**ï¼šå¤šç›®æ ‡å¥–åŠ±ç³»ç»Ÿç”¨äºæ¨¡å¼é€‰æ‹©
- **é«˜æ•ˆè®­ç»ƒ**ï¼šLoRA å‚æ•°é«˜æ•ˆå¾®è°ƒé…åˆ VLLM åŠ é€Ÿ
- **å…¨é¢è¯„ä¼°ç³»ç»Ÿ**ï¼šæ¨¡å—åŒ–çš„è¯„ä¼°ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æŒ‡æ ‡å’Œå¯¹æ¯”åˆ†æ
- **ä¸­è‹±æ–‡æ–‡æ¡£**ï¼šå®Œæ•´çš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
schema-linking-dapo/
â”œâ”€â”€ README.md                    # é¡¹ç›®ä¸»æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ src/                          # æºä»£ç 
â”‚   â”œâ”€â”€ README.md                # æºç è¯¦ç»†æ–‡æ¡£
â”‚   â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–æ–‡ä»¶
â”‚   â”œâ”€â”€ training/                # è®­ç»ƒæ¨¡å—
â”‚   â”‚   â””â”€â”€ grpo.py             # GRPO è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ rewards/                # å¥–åŠ±å‡½æ•°æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ schema_rewards.py     # æ¨¡å¼é€‰æ‹©å¥–åŠ±
â”‚   â”‚   â”œâ”€â”€ format_rewards.py     # æ ¼å¼éªŒè¯å¥–åŠ±
â”‚   â”‚   â””â”€â”€ base_rewards.py       # åŸºç¡€å·¥å…·å¥–åŠ±
â”‚   â”œâ”€â”€ data/                   # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”‚   â””â”€â”€ data_processor.py     # è®­ç»ƒæ•°æ®å‡†å¤‡
â”‚   â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°æ¨¡å—
â”‚   â””â”€â”€ evaluation/            # è¯„ä¼°ç³»ç»Ÿ ğŸ†•
â”‚       â”œâ”€â”€ README.md            # è¯„ä¼°ç³»ç»Ÿè¯¦ç»†æ–‡æ¡£
â”‚       â”œâ”€â”€ __init__.py          # è¯„ä¼°æ¨¡å—å¯¼å‡º
â”‚       â”œâ”€â”€ config.py            # è¯„ä¼°é…ç½®
â”‚       â”œâ”€â”€ utils.py             # è¯„ä¼°å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ data_loader.py       # è¯„ä¼°æ•°æ®åŠ è½½
â”‚       â”œâ”€â”€ model_client.py      # vLLMæ¨¡å‹äº¤äº’
â”‚       â”œâ”€â”€ metrics_calculator.py  # è¯„ä¼°æŒ‡æ ‡è®¡ç®—
â”‚       â”œâ”€â”€ file_handler.py      # è¯„ä¼°ç»“æœä¿å­˜
â”‚       â””â”€â”€ evaluate_qwen_model.py # ä¸»è¯„ä¼°é€»è¾‘
â”œâ”€â”€ configs/                      # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ training_config.yaml      # è®­ç»ƒå‚æ•°
â”œâ”€â”€ scripts/                      # æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ train_dapo_lora.sh        # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ start_vllm.sh            # vLLMæœåŠ¡å¯åŠ¨è„šæœ¬ ğŸ†•
â”‚   â””â”€â”€ run_evaluation.py        # è¯„ä¼°æ‰§è¡Œè„šæœ¬ ğŸ†•
â”œâ”€â”€ data/                         # æ•°æ®é›†
â”‚   â”œâ”€â”€ training_prompt2.csv     # è®­ç»ƒæ•°æ® (8,539æ¡)
â”‚   â””â”€â”€ val_prompt2.csv         # éªŒè¯æ•°æ® (1,004æ¡)
â”œâ”€â”€ outputs/                      # æ¨¡å‹è¾“å‡ºå’Œè¯„ä¼°ç»“æœ
â”‚   â”œâ”€â”€ daapo-Qwen3-0.6B/        # è®­ç»ƒåçš„æ¨¡å‹
â”‚   â””â”€â”€ evaluation/            # è¯„ä¼°ç»“æœ ğŸ†•
â”œâ”€â”€ requirements.txt              # ä¾èµ–é¡¹
â”œâ”€â”€ setup.py                      # å®‰è£…é…ç½®
â””â”€â”€ README_evaluation_simple.md    # è¯„ä¼°ç³»ç»Ÿç®€åŒ–æ–‡æ¡£
```

## ğŸ“Š è¯„ä¼°ç³»ç»Ÿ ğŸ†•

é¡¹ç›®åŒ…å«å®Œæ•´çš„æ¨¡å‹è¯„ä¼°ç³»ç»Ÿï¼Œæ”¯æŒåŸºäº SCHEMA-R1 æ ‡å‡†çš„å¤šç»´åº¦æ€§èƒ½åˆ†æï¼š

### è¯„ä¼°æŒ‡æ ‡
- **EM (Exact Match)**: ç²¾ç¡®åŒ¹é…ï¼Œé¢„æµ‹ä¸çœŸå®æ ‡ç­¾å®Œå…¨ä¸€è‡´
- **Filtered Accuracy**: è¿‡æ»¤å‡†ç¡®ç‡ï¼Œé¢„æµ‹çš„å‡†ç¡®æ€§ï¼ˆç²¾ç¡®ç‡ï¼‰
- **Recall**: å¬å›ç‡ï¼ŒçœŸå®æ ‡ç­¾çš„è¦†ç›–ç‡

### è¯„ä¼°ç»“æœå¯¹æ¯”

| æ¨¡å‹ | è¡¨é€‰æ‹© EM | åˆ—é€‰æ‹© EM | è¡¨é€‰æ‹© Recall | åˆ—é€‰æ‹© Recall |
|------|-----------|-----------|---------------|---------------|
| **Qwen2.5-0.5B (SCHEMA-R1)** | 55.38% | 13.24% | 75.60% | 44.02% |
| **Qwen3-0.6B (åŸºç¡€)** | 42.23% | 19.02% | 55.68% | 44.76% |
| **Qwen3-0.6B + DAPO** | 70.82% | 30.48% | **92.12%** | **72.52%** |

### ğŸ‰ æ€§èƒ½æå‡
- **è¡¨é€‰æ‹©**: EM æå‡ 28.59%ï¼ŒRecall æå‡ 36.44%
- **åˆ—é€‰æ‹©**: EM æå‡ 11.46%ï¼ŒRecall æå‡ 27.76%
- **è¶…è¶ŠåŸºçº¿**: åœ¨è¡¨é€‰æ‹©ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äº SCHEMA-R1 åŸºçº¿

### ğŸ“– å¿«é€Ÿè¯„ä¼°
```bash
# 1. å¯åŠ¨vLLMæœåŠ¡ï¼ˆåŒ…å«LoRAæƒé‡ï¼‰
bash scripts/start_vllm.sh

# 2. è¿è¡Œè¯„ä¼°
python scripts/run_evaluation.py --model_name "dapo-Qwen3-0.6B"

# 3. è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆå¯¹æ¯”ï¼‰
# ä¿®æ”¹ vllm è„šæœ¬ä¸­çš„ LoRA é…ç½®
python scripts/run_evaluation.py --model_name "Qwen3-0.6B"
```

è¯¦ç»†è¯„ä¼°æ–‡æ¡£è¯·å‚è§ï¼š
- [ğŸ“– è¯„ä¼°ç³»ç»Ÿè¯¦ç»†æŒ‡å—](src/evaluation/README.md)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-username/schema-linking-dapo.git
cd schema-linking-dapo

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¼€å‘æ¨¡å¼å®‰è£…é¡¹ç›®
pip install -e .
```

### 2. æ•°æ®å‡†å¤‡

ä½¿ç”¨ SCHEMA-R1 æ•°æ®é›†ï¼ˆ8,539æ¡è®­ç»ƒæ ·æœ¬ï¼‰ï¼š
```bash
# ä¸‹è½½è®­ç»ƒå’ŒéªŒè¯æ•°æ®
# æ¥æº: https://arxiv.org/pdf/2506.11986 (SCHEMA-R1è®ºæ–‡)
# å°†ä¸‹è½½çš„æ–‡ä»¶æ”¾åˆ° data/ ç›®å½•ï¼š
# data/training_prompt2.csv (è®­ç»ƒæ•°æ®)
# data/val_prompt2.csv (éªŒè¯æ•°æ®, 1,004æ¡)

# å¤„ç†æ•°æ®ï¼Œç”Ÿæˆè®­ç»ƒæ•°æ®
python src/data/data_processor.py
```

### 3. æ¨¡å‹è®­ç»ƒ

```bash
# ç»™è®­ç»ƒè„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
chmod +x scripts/train_dalo_lora.sh

# è¿è¡Œè®­ç»ƒï¼ˆåŸºäº8,539æ¡æ ·æœ¬ï¼‰
./scripts/train_dapo_lora.sh
```

### 4. æ¨¡å‹è¯„ä¼°

```bash
# å¯åŠ¨vLLMæœåŠ¡ï¼ˆåŒ…å«è®­ç»ƒåçš„LoRAæƒé‡ï¼‰
bash scripts/start_vllm.sh

# è¿è¡Œå®Œæ•´è¯„ä¼°
python scripts/run_evaluation.py --model_name "dapo-Qwen3-0.6B"

# è°ƒè¯•æ¨¡å¼ï¼ˆåªå¤„ç†å°‘é‡æ ·æœ¬ï¼‰
python scripts/run_evaluation.py --debug --debug_samples 50
```

## ğŸ† å¥–åŠ±å‡½æ•°ä½“ç³» ğŸ†•

é¡¹ç›®å®ç°äº†ä¸ SCHEMA-R1 ä¸åŒçš„å¥–åŠ±å‡½æ•°è®¾è®¡ï¼š

### å½“å‰é¡¹ç›®å¥–åŠ±å‡½æ•°

#### Schema Rewards (æ¨¡å¼å¥–åŠ±)
- **è¡¨é€‰æ‹©å¥–åŠ±**: `æ­£ç¡®é¢„æµ‹çš„è¡¨æ•°é‡ / çœŸå®è¡¨æ€»æ•°` (0.0-1.0)
- **è¡¨é€‰æ‹©æƒ©ç½š**: `-(é”™è¯¯è¡¨æ•°é‡ / ç”Ÿæˆè¡¨æ€»æ•°)` (-1.0-0.0)
- **åˆ—é€‰æ‹©å¥–åŠ±**: `æ­£ç¡®é¢„æµ‹çš„åˆ—æ•°é‡ / çœŸå®åˆ—æ€»æ•°` (0.0-1.0)
- **åˆ—é€‰æ‹©æƒ©ç½š**: `-(é”™è¯¯åˆ—æ•°é‡ / ç”Ÿæˆåˆ—æ€»æ•°)` (-1.0-0.0)

#### Format Rewards (æ ¼å¼å¥–åŠ±)
- **æ€è€ƒæ ‡ç­¾æƒ©ç½š**: æ£€æŸ¥ `æ€è€ƒæ ‡ç­¾` å®Œæ•´æ€§ (0.0/-1.0)
- **JSONæ ¼å¼éªŒè¯**: JSONè§£æéªŒè¯ (1.0/-1.0)

#### Base Rewards (åŸºç¡€å¥–åŠ±)
- **è½¯é•¿åº¦æƒ©ç½š**: åŸºäºDAPOè®ºæ–‡çš„è½¯è¾¹ç•Œæƒ©ç½šæœºåˆ¶
- **å‚æ•°**: æœ€å¤§é•¿åº¦=1024, è½¯æƒ©ç½šç¼“å­˜=128

### SCHEMA-R1 å¥–åŠ±å‡½æ•°

#### Format Reward (æ ¼å¼å¥–åŠ±)
- æ ¼å¼æˆåŠŸ + æ ‡ç­¾æ£€æŸ¥ï¼ˆåŒéªŒè¯æœºåˆ¶ï¼‰
- ç¡¬è¾¹ç•Œé•¿åº¦æ§åˆ¶

#### Reasoning Length Reward (æ¨ç†é•¿åº¦å¥–åŠ±)
- éè¿ç»­äºŒå…ƒå¥–åŠ±ï¼ˆ0æˆ–1ï¼‰
- é¢„è®¾é•¿åº¦è¾¹ç•Œæ§åˆ¶

#### Schema Linking Reward (æ¨¡å¼é“¾æ¥å¥–åŠ±)
- å¤æ‚æ•°å­¦å…¬å¼è®¡ç®—ï¼ˆRtmax/Rcmaxæƒé‡æœºåˆ¶ï¼‰
- åˆ†å±‚å¥–åŠ±ï¼šè¡¨é¢„æµ‹ > åˆ—é¢„æµ‹æƒé‡

### ğŸ¯ å¥–åŠ±å‡½æ•°å¯¹æ¯”

| ç‰¹æ€§ | SCHEMA-R1 | å½“å‰é¡¹ç›® |
|------|-----------|----------|
| **æ•°æ®æ ¼å¼** | çº¯æ–‡æœ¬ | JSONç»“æ„åŒ– |
| **æ ¼å¼æ£€æŸ¥** | æ­£åˆ™åŒ¹é… | JSONè§£æéªŒè¯ |
| **é•¿åº¦æ§åˆ¶** | ç¡¬è¾¹ç•Œ | è½¯è¾¹ç•Œ |
| **è¡¨åˆ—æƒé‡** | Rtmax > Rcmax | ç‹¬ç«‹å¥–åŠ±/æƒ©ç½š |
| **å®ç°å¤æ‚åº¦** | æ•°å­¦å…¬å¼å¤æ‚ | ç®€å•æ¯”ä¾‹è®¡ç®— |

## ğŸ› ï¸ æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒæ¡†æ¶
- **PyTorch**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **TRL**: Transformers Reinforcement Learning
- **vLLM**: é«˜æ€§èƒ½æ¨ç†å¼•æ“
- **Transformers**: HuggingFace æ¨¡å‹åº“

### è®­ç»ƒæŠ€æœ¯
- **DAPO**: ç›´æ¥ä¼˜åŠ¿ç­–ç•¥ä¼˜åŒ–
- **GRPO**: é€šç”¨ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–
- **LoRA**: ä½ç§©é€‚åº”å‚æ•°å¾®è°ƒ
- **é‡è¦æ€§é‡‡æ ·**: è®­ç»ƒä¼˜åŒ–æŠ€æœ¯

### æ¨ç†åŠ é€Ÿ
- **VLLM**: å…±ç½®æ¨¡å¼æ¨ç†
- **4-bité‡åŒ–**: å†…å­˜ä¼˜åŒ–
- **å¹¶å‘å¤„ç†**: æ‰¹é‡æ¨ç†åŠ é€Ÿ

## âš™ï¸ é…ç½®

### è®­ç»ƒé…ç½® (`configs/training_config.yaml`)
```yaml
# å…³é”®å‚æ•°
training:
  num_iterations: 2
  learning_rate: 1e-5
  loss_type: "dapo"
  epsilon: 0.2
  epsilon_high: 0.28

model:
  base_model: "/mnt/d/modelscope/Qwen3-0.6B"
  use_peft: true
  load_in_4bit: true

# VLLM æ¨ç†é…ç½®
vllm:
  enabled: true
  mode: "colocate"
  gpu_memory_utilization: 0.5
```

### è¯„ä¼°é…ç½®
- API æœåŠ¡é…ç½®
- å¤šæŒ‡æ ‡è¯„ä¼°ç³»ç»Ÿ
- æŠ¥å‘Šç”Ÿæˆå’Œå¯è§†åŒ–
- æ‰¹é‡è¯„ä¼°æ”¯æŒ

## ğŸ“ˆ æ€§èƒ½æˆæœ

### è®­ç»ƒæ•°æ®
- **æ•°æ®é›†**: SCHEMA-R1 (8,539æ¡æ ·æœ¬)
- **æ ¼å¼**: JSONç»“æ„åŒ–è¾“å‡º
- **æ— éœ€SFT**: ç›´æ¥DAPOè®­ç»ƒ

### æ€§èƒ½æŒ‡æ ‡
- **æ˜¾è‘—æå‡**: ç›¸æ¯”åŸºç¡€æ¨¡å‹ï¼ŒDAPOå¾®è°ƒåæ€§èƒ½å¤§å¹…æå‡
- **è¶…è¶ŠåŸºçº¿**: åœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šè¶…è¶ŠSCHEMA-R1è®ºæ–‡ç»“æœ
- **é«˜æ•ˆæ¨ç†**: LoRAå¾®è°ƒ + VLLMæ¨ç†åŠ é€Ÿ

### å®é™…åº”ç”¨ä»·å€¼
- **æ•°æ®åº“æŸ¥è¯¢**: å‡†ç¡®çš„è¡¨å’Œåˆ—é€‰æ‹©
- **æ•ˆç‡æå‡**: å‡å°‘ä¸å¿…è¦çš„æ•°æ®æ£€ç´¢
- **æˆæœ¬é™ä½**: ç²¾ç¡®çš„SQLæŸ¥è¯¢ç”Ÿæˆ

## ğŸ”§ å¼€å‘æŒ‡å—

### è¯„ä¼°ç³»ç»Ÿæ‰©å±•
```python
# è¯„ä¼°ç³»ç»Ÿä½äº src/evaluation/ ç›®å½•
# æ”¯æŒå¤šç§è¯„ä¼°æ¨¡å¼å’Œè‡ªå®šä¹‰æŒ‡æ ‡

from src.evaluation import MetricsCalculator, EvaluationRunner

# æ·»åŠ è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡
calculator = MetricsCalculator(
    weights={'table_f1': 0.4, 'column_f1': 0.4}
)

# è¿è¡Œè¯„ä¼°
runner = EvaluationRunner(config)
results = runner.run_evaluation()
```

### å¥–åŠ±å‡½æ•°æ‰©å±•
```python
# åœ¨ src/rewards/ ç›®å½•ä¸‹æ·»åŠ æ–°å¥–åŠ±å‡½æ•°
def custom_reward(completions, **kwargs):
    # è‡ªå®šä¹‰å¥–åŠ±é€»è¾‘
    return [0.5 for _ in completions]

# åœ¨è®­ç»ƒé…ç½®ä¸­å¼•ç”¨
--reward_funcs "src.rewards.custom.custom_reward"
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿è´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

### å¼€å‘è§„èŒƒ
- ä»£ç æ¨¡å—åŒ–è®¾è®¡
- å®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£
- å•å…ƒæµ‹è¯•è¦†ç›–
- ç±»å‹æ³¨è§£æ”¯æŒ

## ğŸ“š å‚è€ƒæ–‡çŒ®

### è®ºæ–‡èµ„æ–™
- **DAPOè®ºæ–‡**: [DAPO: An Open-Source LLM Reinforcement Learning System at Scale](https://arxiv.org/abs/2503.14476)
- **SCHEMA-R1è®ºæ–‡**: [A Reasoning Training Approach for Schema Linking in Text-to-SQL Task](https://arxiv.org/pdf/2506.11986)
- **GRPOè®ºæ–‡**: [Generalized Relative Policy Optimization](https://arxiv.org/abs/2402.03300)

### æ¡†æ¶æ–‡æ¡£
- [TRLæ–‡æ¡£](https://huggingface.co/docs/trl)
- [vLLMæ–‡æ¡£](https://vllm.readthedocs.io/)
- [Transformersæ–‡æ¡£](https://huggingface.co/docs/transformers)

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache License 2.0 è®¸å¯è¯ - è¯¦æƒ…è¯·æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- **SCHEMA-R1è®ºæ–‡ä½œè€…**: æä¾›çš„åŸå§‹æ•°æ®é›†å’Œè¯„ä¼°æ–¹æ³•
- **TRLå›¢é˜Ÿ**: æä¾›çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶
- **VLLMå›¢é˜Ÿ**: æä¾›çš„é«˜æ•ˆæ¨ç†åŠ é€ŸæŠ€æœ¯
- **å¼€æºç¤¾åŒº**: åœ¨ç®—æ³•å’Œå·¥å…·é“¾æ–¹é¢çš„è´¡çŒ®

## ğŸ”— ç›¸å…³é“¾æ¥

- **SCHEMA-R1é¡¹ç›®**: [GitHub Repository](https://github.com/hongWin/Schema-R1)
- **TRLæ¡†æ¶**: [HuggingFace TRL](https://huggingface.co/docs/trl)
- **VLLMå¼•æ“**: [VLLM Project](https://github.com/vllm-project/vllm)
- **è¯„ä¼°æ–‡æ¡£**: [è¯„ä¼°ç³»ç»Ÿè¯¦ç»†æŒ‡å—](src/evaluation/README.md)

---

*æœ€åæ›´æ–°: 2024å¹´11æœˆ*